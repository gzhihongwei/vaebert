{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb87edb-ef09-4f2b-82b8-f165c7c4f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441214e0-b738-474b-9555-ee043a7622b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shapenet/partnet_metadata.json', 'r') as f:\n",
    "    partnet_metadata = json.load(f)\n",
    "metadata_zip = list(zip(partnet_metadata['model_ids'], partnet_metadata['category_ids'], partnet_metadata['captions']))\n",
    "metadata_zip = sorted(metadata_zip, key=lambda x: str(x[1]) + str(x[0]))\n",
    "with open('shapenet/partnet_metadata_sorted_zip.json', 'w') as f:\n",
    "    json.dump(metadata_zip, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a430249-a1ec-44fd-b51b-34f94b446232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_ids', 'captions', 'category_ids'])\n"
     ]
    }
   ],
   "source": [
    "print(partnet_metadata.keys())\n",
    "# with open('shapenet/binvox_metadata.json', 'r') as f:\n",
    "#     binvox_metadata = json.load(f)\n",
    "# print(binvox_metadata[\"model_ids\"][:20])\n",
    "# print(partnet_metadata[\"model_ids\"][:20])\n",
    "# issue = 0\n",
    "# for model_id in partnet_metadata[\"model_ids\"]:\n",
    "#     if model_id not in binvox_metadata[\"model_ids\"]:\n",
    "#         issue += 1\n",
    "# print(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db66f398-6156-4a6c-8cd7-35c2a4012698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13919\n"
     ]
    }
   ],
   "source": [
    "print(len(metadata_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e9787a-4188-4609-b1c0-23bb9d85375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 204, 668, 809, 5558, 6092, 6606, 7160, 8374, 8805, 9014, 13919]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "current_cat_id = \"\"\n",
    "cat_ids = []\n",
    "indexes = []\n",
    "for i, model_data in enumerate(metadata_zip):\n",
    "    _, cat_id, _ = model_data\n",
    "    if cat_id != current_cat_id:\n",
    "        cat_ids.append(cat_id)\n",
    "        indexes.append(i)\n",
    "        current_cat_id = cat_id\n",
    "indexes.append(len(metadata_zip))\n",
    "print(indexes)\n",
    "print(len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b64e2af-6e04-43a5-9a5b-4187d2ed0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_ids [2818832, 2876657, 2880940, 3001627, 3046257, 3325088, 3593526, 3636649, 3642806, 3797390, 4379243]\n",
      "indexes [0, 204, 668, 809, 5558, 6092, 6606, 7160, 8374, 8805, 9014, 13919]\n"
     ]
    }
   ],
   "source": [
    "print(\"cat_ids\", cat_ids)\n",
    "print(\"indexes\", indexes)\n",
    "cat_id_suffled_ranges = []\n",
    "for i in range(len(indexes) - 1):\n",
    "    cat_range = [j for j in range(indexes[i], indexes[i + 1])]\n",
    "    random.shuffle(cat_range)\n",
    "    cat_id_suffled_ranges.append(cat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e2c65b-12dc-43d8-84df-4d12d3e9188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201, 128, 150, 17, 61, 88, 122, 66, 60, 127, 100, 98, 139, 57, 82, 144, 89, 1, 5, 130]\n",
      "13919\n",
      "12521 1398 13919\n"
     ]
    }
   ],
   "source": [
    "print(cat_id_suffled_ranges[0][0:20])\n",
    "train_indexes = []\n",
    "test_indexes = []\n",
    "total_num = 0\n",
    "for cat_range in cat_id_suffled_ranges:\n",
    "    total_num += len(cat_range)\n",
    "print(total_num)\n",
    "for cat_range in cat_id_suffled_ranges:\n",
    "    train_number = int(len(cat_range) * 0.9)\n",
    "    train_indexes.extend(cat_range[:train_number])\n",
    "    test_indexes.extend(cat_range[train_number:])\n",
    "print(len(train_indexes), len(test_indexes), len(train_indexes)+len(test_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02109b85-ed3e-4649-a05d-05f26328ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shapenet/train_indexes.json', 'w') as f:\n",
    "    json.dump(train_indexes, f)\n",
    "with open('shapenet/test_indexes.json', 'w') as f:\n",
    "    json.dump(test_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5662e58-88a5-44a4-bbe8-ba364d8730ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12521\n",
      "[201, 128, 150, 17, 61, 88, 122, 66, 60, 127, 100, 98, 139, 57, 82, 144, 89, 1, 5, 130]\n",
      "1398\n",
      "[103, 31, 26, 20, 75, 92, 199, 181, 118, 32, 135, 180, 102, 95, 2, 19, 119, 8, 184, 137]\n"
     ]
    }
   ],
   "source": [
    "with open('shapenet/train_indexes.json', 'r') as f:\n",
    "    indexes = json.load(f)\n",
    "    print(len(indexes))\n",
    "    print(indexes[0:20])\n",
    "with open('shapenet/test_indexes.json', 'r') as f:\n",
    "    indexes = json.load(f)\n",
    "    print(len(indexes))\n",
    "    print(indexes[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331cf586-47c9-460c-bef4-d1faf33c9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'int'> <class 'str'>\n",
      "['bunk bed that is short and average length and skinny.  it has two posts . it has two beds .', 'platform bed that is very thick and short and skinny.  it has four posts . it has two beds .', 'bunk that is short and average length and wide.  it has a ladder.  it has four posts . it has two beds .', 'platform bed that is thin and long and average width.  it has a headboard.  it has two pillows . it has one bed .', 'bunk bed that is short and very short and wide.  it has a ladder.  it has four posts . it has two beds .', 'bunk bed that is tall and short and wide.  it has a ladder.  it has many posts . it has two beds .', 'bunk bed that is tall and short and average width.  it has a headboard.  it has three pillows . it has one bed .', 'bunk bed that is average height and average length and average width.  it has a ladder.  it has four pillows . it has many posts . it has two beds .', 'platform bed that is average thickness and average length and wide.  it has a headboard.  it has three pillows . it has one bed .', 'platform bed that is short and square and large.  it has one foot . it has four legs . it has one shelf .', 'bunk bed that is short and average length and average width.  it has a ladder.  it has three pillows . it has many posts . it has two beds .', 'platform bed that is very thin and very long and very wide.  it has one bed .', 'platform bed that is average thickness and average length and average width.  it has a headboard.  it has one bed .', 'platform bed that is thin and long and very skinny.  it has a ladder.  it has two beds .', 'headboard bed that is thin and long and average width.  it has a headboard.  it has one bed .', 'bunk that is short and average length and average width.  it has a ladder.  it has five pillows . it has five posts . it has four beds .', 'bunk bed that is short and average length and skinny.  it has a ladder.  it has two pillows . it has four posts . it has two beds .', 'headboard bed that is average thickness and average length and wide.  it has a headboard.  it has six pillows . it has one bed .', 'bunk that is short and long and skinny.  it has a ladder.  it has two pillows . it has two beds .', 'bunk bed that is short and average length and skinny.  it has two pillows . it has many posts . it has two beds .', 'platform bed that is average thickness and average length and average width.  it has a headboard.  it has three pillows . it has one bed .', 'headboard bed that is thin and very long and very wide.  it has a headboard.  it has one bed .', 'bunk that is short and average length and skinny.  it has a ladder.  it has many posts . it has two beds .', 'bunk bed that is short and long and very skinny.  it has a ladder.  it has three pillows . it has many posts . it has three beds .', 'platform bed that is average thickness and average length and wide.  it has a headboard.  it has three pillows . it has one bed .', 'bunk bed that is tall and short and average width.  it has a ladder.  it has two pillows . it has many posts . it has two beds .', 'bunk that is average height and short and skinny.  it has a ladder.  it has many posts . it has two beds .', 'headboard bed that is average thickness and long and average width.  it has a headboard.  it has one bed .', 'bunk that is short and average length and average width.  it has a ladder.  it has four posts . it has two beds .', 'bunk bed that is very short and very long and average width.  it has four posts . it has one bed .', 'bunk bed that is average height and average length and average width.  it has a ladder.  it has many posts . it has two beds .', 'platform bed that is very thin and very long and wide.  it has a headboard.  it has two pillows . it has one bed .', 'bunk bed that is average height and average length and average width.  it has a ladder.  it has many posts . it has two beds .', 'platform bed that is very thin and very short and very wide.  it has a headboard.  it has one bed .', 'platform bed that is very thin and very long and wide.  it has a headboard.  it has one bed .', 'bunk that is average height and short and skinny.  it has a ladder.  it has many posts . it has two beds .', 'platform bed that is thick and short and skinny.  it has a ladder.  it has many posts . it has two beds .', 'bunk that is tall and very short and skinny.  it has a ladder.  it has four posts . it has one bed .', 'platform bed that is very thick and short and average width.  it has a headboard.  it has five pillows . it has one bed .', 'platform bed that is thin and long and average width.  it has a headboard.  it has one bed .', 'platform bed that is average thickness and very short and wide.  it has a headboard.  it has four pillows . it has one bed .', 'bunk that is short and average length and skinny.  it has a ladder.  it has four pillows . it has six posts . it has two beds .', 'platform bed that is average thickness and long and average width.  it has one pillow . it has two beds .', 'bed that is thick and average length and average width.  it has a ladder.  it has many posts . it has two beds .', 'platform bed that is average thickness and average length and wide.  it has a headboard.  it has three pillows . it has one bed .', 'bunk that is average height and short and average width.  it has a headboard.  it has a ladder.  it has two beds .', 'bunk bed that is tall and short and average width.  it has one pillow . it has four posts . it has one bed .', 'bunk bed that is short and average length and skinny.  it has a ladder.  it has many posts . it has two beds .', 'bunk bed that is average height and average length and average width.  it has a ladder.  it has two pillows . it has four posts . it has two beds .', 'platform bed that is average thickness and long and average width.  it has a headboard.  it has three pillows . it has one bed .']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "model_ids, categories, captions = zip(*metadata_zip)\n",
    "print(type(model_ids[0]), type(categories[0]), type(captions[0]))\n",
    "with h5py.File('shapenet/binvox.hdf5','w') as hf:\n",
    "    np_captions = np.array([str(i).strip() for i in captions], dtype=h5py.special_dtype(vlen=str)) \n",
    "    hf.create_dataset('captions', data=np_captions)\n",
    "    np_model_ids = np.array(model_ids, dtype=h5py.special_dtype(vlen=str))\n",
    "    hf.create_dataset('model_ids', data=np_model_ids)\n",
    "    np_category_ids = np.array(categories)\n",
    "    hf.create_dataset('category_ids', data=np_category_ids)\n",
    "with h5py.File('shapenet/binvox.hdf5','r') as hf:\n",
    "    print(list(i.decode() for i in hf['captions'][:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c8a44-ab9e-49c5-a25f-1fe7732fd75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
